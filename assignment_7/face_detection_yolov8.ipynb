{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2a9466e",
   "metadata": {},
   "source": [
    "### data ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3405799",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "def unzip_file(zip_path, extract_to='.'):\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_to)\n",
    "\n",
    "# Unzip manually downloaded files\n",
    "unzip_file('WIDER_train.zip', 'wider_face/')\n",
    "unzip_file('WIDER_val.zip', 'wider_face/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01e176d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "for split in ['train', 'val']:\n",
    "    Path(f'datasets/face/images/{split}').mkdir(parents=True, exist_ok=True)\n",
    "    Path(f'datasets/face/labels/{split}').mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bdea077",
   "metadata": {},
   "source": [
    "### **Dataset Preparation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f085f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_wider_annotations(image_dir, annotation_file, output_label_dir, output_img_dir):\n",
    "\n",
    "    os.makedirs(output_label_dir, exist_ok=True)\n",
    "    os.makedirs(output_img_dir, exist_ok=True)\n",
    "\n",
    "    with open(annotation_file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    idx = 0\n",
    "    while idx < len(lines):\n",
    "        filename = lines[idx].strip()\n",
    "        idx += 1\n",
    "\n",
    "        if idx >= len(lines):\n",
    "            break  \n",
    "\n",
    "        try:\n",
    "            num_faces = int(lines[idx].strip())\n",
    "        except ValueError:\n",
    "            print(f\"âš ï¸ Skipped invalid line: {lines[idx].strip()}\")\n",
    "            break\n",
    "\n",
    "        idx += 1\n",
    "\n",
    "        image_path = os.path.join(image_dir, filename)\n",
    "        label_path = os.path.join(output_label_dir, os.path.splitext(filename)[0] + '.txt')\n",
    "        label_dir = os.path.dirname(label_path)\n",
    "        os.makedirs(label_dir, exist_ok=True)\n",
    "\n",
    "        output_img_path = os.path.join(output_img_dir, filename)\n",
    "        output_img_dirname = os.path.dirname(output_img_path)\n",
    "        os.makedirs(output_img_dirname, exist_ok=True)\n",
    "        if os.path.exists(image_path):\n",
    "            cv2.imwrite(output_img_path, cv2.imread(image_path))\n",
    "        else:\n",
    "            print(f\"ðŸš« Image not found: {image_path}\")\n",
    "            continue\n",
    "\n",
    "        with open(label_path, 'w') as label_file:\n",
    "            for _ in range(num_faces):\n",
    "                if idx >= len(lines):\n",
    "                    break  \n",
    "                box = list(map(int, lines[idx].strip().split()))\n",
    "                x, y, w, h = box[:4]\n",
    "                cx = x + w / 2\n",
    "                cy = y + h / 2\n",
    "                label_file.write(f\"0 {cx} {cy} {w} {h}\\n\")  \n",
    "                idx += 1\n",
    "\n",
    "\n",
    "# Run conversion\n",
    "process_wider_annotations(\n",
    "    image_dir='wider_face/WIDER_train/images',\n",
    "    annotation_file='wider_face/wider_face_split/wider_face_train_bbx_gt.txt',\n",
    "    output_label_dir='datasets/face/labels/train',\n",
    "    output_img_dir='datasets/face/images/train'\n",
    ")\n",
    "\n",
    "process_wider_annotations(\n",
    "    image_dir='wider_face/WIDER_val/images',\n",
    "    annotation_file='wider_face/wider_face_split/wider_face_val_bbx_gt.txt',\n",
    "    output_label_dir='datasets/face/labels/val',\n",
    "    output_img_dir='datasets/face/images/val'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ce6993",
   "metadata": {},
   "outputs": [],
   "source": [
    "yaml_content = \"\"\"\n",
    "path: datasets/face\n",
    "train: images/train\n",
    "val: images/val\n",
    "\n",
    "nc: 1\n",
    "names: ['face']\n",
    "\"\"\"\n",
    "\n",
    "with open(\"face.yaml\", \"w\") as f:\n",
    "    f.write(yaml_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7afe514e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load pretrained model\n",
    "model = YOLO('yolov8n.pt')\n",
    "\n",
    "model.model.fuse()\n",
    "\n",
    "for param in list(model.model.parameters())[:-10]:\n",
    "    param.requires_grad = False\n",
    "\n",
    "\n",
    "# Start training\n",
    "model.train(\n",
    "    data='face.yaml',\n",
    "    epochs=15,\n",
    "    imgsz=640,\n",
    "    batch=16,\n",
    "    name='yolov8_face'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476f8e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import random\n",
    "\n",
    "# Load your fine-tuned model\n",
    "model = YOLO(\"runs/detect/yolov8_face/weights/best.pt\")\n",
    "\n",
    "# Load the uploaded image\n",
    "image_path = \"face_img.jpg\"\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "# Predict with low confidence threshold\n",
    "results = model(image_path, conf=0.1)[0]\n",
    "\n",
    "# Show number of detected faces\n",
    "print(f\"Detected {len(results.boxes)} faces\")\n",
    "\n",
    "# Draw a random color box around each detected face\n",
    "for box in results.boxes:\n",
    "    x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "    conf = float(box.conf[0])\n",
    "    color = [random.randint(0, 255) for _ in range(3)]\n",
    "    cv2.rectangle(image, (x1, y1), (x2, y2), color, 2)\n",
    "    cv2.putText(image, f\"{conf:.2f}\", (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "\n",
    "# Save the output image\n",
    "output_path = \"predicted_faces.jpg\"\n",
    "cv2.imwrite(output_path, image)\n",
    "print(f\"âœ… Saved output to: {output_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
